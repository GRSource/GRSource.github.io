(window.webpackJsonp=window.webpackJsonp||[]).push([[68],{611:function(v,_,a){"use strict";a.r(_);var t=a(65),i=Object(t.a)({},(function(){var v=this,_=v.$createElement,a=v._self._c||_;return a("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[a("h1",{attrs:{id:"直播"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#直播"}},[v._v("#")]),v._v(" 直播")]),v._v(" "),a("h2",{attrs:{id:"弹幕"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#弹幕"}},[v._v("#")]),v._v(" 弹幕")]),v._v(" "),a("h3",{attrs:{id:"barragerenderer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#barragerenderer"}},[v._v("#")]),v._v(" BarrageRenderer")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("BarrageSprite")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("BarrageFloatSprite")]),v._v(" "),a("ul",[a("li",[v._v("BarrageFloatImageSprite")]),v._v(" "),a("li",[v._v("BarrageFloatTextSprite")])])]),v._v(" "),a("li",[a("p",[v._v("BarrageWalkSprite")]),v._v(" "),a("ul",[a("li",[v._v("BarrageWalkImageSprite")]),v._v(" "),a("li",[v._v("BarrageWalkTextSprite")])])])])])]),v._v(" "),a("h3",{attrs:{id:"性能瓶颈"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#性能瓶颈"}},[v._v("#")]),v._v(" 性能瓶颈")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("弹幕阴影")]),v._v(" "),a("ul",[a("li",[v._v("用NSStrokeColorAttributeName替代阴影")])])]),v._v(" "),a("li",[a("p",[v._v("弹幕量大")]),v._v(" "),a("ul",[a("li",[v._v("可以采用异步绘制将弹幕合成一张图片提交给layer")])])])]),v._v(" "),a("h2",{attrs:{id:"视频相关理论"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频相关理论"}},[v._v("#")]),v._v(" 视频相关理论")]),v._v(" "),a("h3",{attrs:{id:"视频"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频"}},[v._v("#")]),v._v(" 视频")]),v._v(" "),a("p",[v._v("根据人眼视觉暂留原理，每秒超过 24 帧的图像变化看上去是平滑连续的，这样的连续画面叫视频。")]),v._v(" "),a("h3",{attrs:{id:"分辨率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分辨率"}},[v._v("#")]),v._v(" 分辨率")]),v._v(" "),a("p",[v._v("分辨率是以横向和纵向的像素数量来衡量的，表示平面像素的精细程度。视频精细程度并不只取决于视频分辨率，还取决于屏幕分辨率。\n1080P的P指Progressive scan（逐行扫描），即垂直方向像素点，也就是“高”，所以1920X1080叫1080P，不叫1920P。分辨率影响图像大小，与图像大小成正比：分辨率越高，图像越大；分辨率越低，图像越小。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("上采样")]),v._v(" "),a("p",[v._v("当720P的视频在1080P屏幕上播放时，需要将图像放大，放大操作也叫上采样。上采样几乎都是采用内插值方法，即在原有图像的像素点之间采用合适的插值算法插入新的元素，所以图像放大也称为图像插值。")]),v._v(" "),a("p",[v._v("邻插值算法、双线性插值法、双三次插值法，除此之外还有很多更复杂效果更有的算法，比如小波插值、分形等等。")])]),v._v(" "),a("li",[a("p",[v._v("下采样")]),v._v(" "),a("p",[v._v("当1080P的视频在720P屏幕上播放时，需要将图像缩小，缩小操作也叫下采样。")]),v._v(" "),a("p",[v._v("下采样的定义为：对于一个样值序列，间隔几个样值取样一次，得到新序列。\n对于一幅分辨率为 MN 的图像，对其进行 s 倍下采样，即得到 (M/s)(N/s) 分辨率的图像（s 应为 M、N 的公约数），就是把原始图像 s*s 窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值。\n最佳体验为屏幕与视频分辨率相同且全屏播放，视频分辨率过高的话屏幕没有能力去呈现，视频分辨率过低的话无法发挥屏幕的能力。")])])]),v._v(" "),a("h3",{attrs:{id:"码率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#码率"}},[v._v("#")]),v._v(" 码率")]),v._v(" "),a("p",[v._v("比特率即码率，在不同领域有不同的含义，在多媒体领域，指单位时间播放音频或视频的比特数，可以理解成吞吐量或带宽。\n单位为 bps , 即 bits per second，每秒传输的数据量，常用单位有：kbps、mbps 等。")]),v._v(" "),a("p",[v._v("计算公式：码率（kbps）= 文件大小（kb）/ 时长（s）")]),v._v(" "),a("p",[v._v("通俗一点理解就是取样率，取样率越大，精度就越高，图像质量越好，但数据量也越大，所以要找到一个平衡点：用最低的比特率达到最少的失真。\n在一个视频中，不同时段画面的复杂程度是不同的，比如高速变化的场景和几乎静止的场景，所需的数据量也是不同的，若都使用同一种比特率是不太合理的，所以引入了动态比特率。")]),v._v(" "),a("p",[v._v("编码器每秒编出的数据大小，单位是kbps，比如800kbps代表编码器每秒产生800kb（或100KB）的数据。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("动态比特率")]),v._v(" "),a("p",[v._v("简称为 VBR，即 Variable Bit Rate，比特率可以随着图像复杂程度的不同而随之变化。\n图像内容简单的片段采用较小的码率，图像内容复杂的片段采用较大的码率，这样既保证了播放质量，又兼顾了数据量的限制。\n比如 RMVB 视频文件，其中的 VB 就是指 VBR，表示采用动态比特率编码方式，达到播放质量与体积兼得的效果。")])]),v._v(" "),a("li",[a("p",[v._v("静态比特率")]),v._v(" "),a("p",[v._v("简称为 CBR，即 Constant Bit Rate，比特率恒定。\n图像内容复杂的片段质量不稳定，图像内容简单的片段质量较好。\n上面列出的计算公式显然是针对 CBR ，除 VBR 和 CBR 外，还有 CVBR（Constrained VariableBit Rate） 、ABR (Average Bit Rate) 等等。")])])]),v._v(" "),a("h3",{attrs:{id:"采样率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#采样率"}},[v._v("#")]),v._v(" 采样率")]),v._v(" "),a("p",[v._v("每秒从连续信号中提取并组成离散信号的采样个数，单位为赫兹（Hz）。\n对于取样率、采样率和抽样率，没必要纠结它们的区别，都是同义词。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("音频中的采样率")]),v._v(" "),a("p",[v._v("指把音频信号数字化后 1 个通道 1 秒钟采取多少个样本，如 44.1kHz 的采样率，就是指 1 个通道 1 秒钟有 44.1k 个数据。")])]),v._v(" "),a("li",[a("p",[v._v("视频中的采样率")]),v._v(" "),a("p",[v._v("视频一般不标识采样率属性。")]),v._v(" "),a("p",[v._v("采样率本身就是一个可泛化的概念，对于视频来说，若非要用采样率来描述的话，那就要分为两个层面：帧频和场频。\n从帧频层面来说，采样率就是指帧率，指 1 秒钟显示多少帧图像。\n从场频层面来说，采样率就是指像素频率，指 1 秒钟显示多少个像素。\n像素频率是显示器的一个指标，可以理解成显示器的最大带宽，可以起到限制分辨率和刷新率的作用，根据含义可得出一个公式：\n像素频率 = 帧率 X 帧像素数量")]),v._v(" "),a("p",[v._v("帧率 = 138.5 x 1024 x 1024 / 1920 / 1080 ≈ 70.04 ， 得出的 70Hz 为正常的帧率范围，也可以反向确定对像素频率的理解是正确的。")])])]),v._v(" "),a("h3",{attrs:{id:"帧率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#帧率"}},[v._v("#")]),v._v(" 帧率")]),v._v(" "),a("p",[v._v("用于测量显示帧数的量度。单位为 FPS（Frames per Second，每秒显示帧数）或赫兹（Hz）。\n前面提到每秒超过 24 帧的图像变化看上去是平滑连续的，这是针对电影等视频而言，对游戏来说 24 帧是不流畅的。\n为什么 24fps 的电影感觉流畅，而 24fps 的游戏就感觉很卡呢？\n第一个原因：两者图像生成原理不同\n电影的一帧在一段时间曝光，每一帧都包含一段时间的信息，而游戏的画面则是由显卡计算生成的，一帧只包含那一瞬间的信息。\n前者为电影的一帧，后者为游戏的一帧，可以看到在电影中动作会出现拖影，给人以动感的效果，连贯而不卡。\n第二个原因：电影的FPS是稳定的，而游戏则是不稳定的\n电影若为 24fps，那就表示每隔 1/24 秒刷新一次画面，帧间隔是固定的。\n游戏若为 60fps，表示大约每隔 1/60 秒刷新一次画面，帧间隔是不稳定的，即使 1 秒能显示 60 帧，那也可能是前半秒显示了 59 帧，后半秒显示了 1 帧。")]),v._v(" "),a("ul",[a("li",[v._v("影响画面流畅度，与画面流畅度成正比：帧率越大，画面越流畅；帧率越小，画面越有跳动感。如果码率为变量，则帧率也会影响体积，帧率越高，每秒钟经过的画面越多，需要的码率也越高，体积也越大。帧率就是在1秒钟时间里传输的图片的帧数，也可以理解为图形处理器每秒钟能够刷新几次。")])]),v._v(" "),a("h3",{attrs:{id:"视频编码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频编码"}},[v._v("#")]),v._v(" 视频编码")]),v._v(" "),a("p",[v._v("通过特定的压缩技术，将某个视频格式的文件转换成另一种视频格式。\n视频数据在时域和空域层面都有极强的相关性，这也表示有大量的时域冗余信息和空域冗余信息，压缩技术就是去掉数据中的冗余信息。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("去除时域冗余信息")]),v._v(" "),a("p",[v._v("运动补偿：通过先前的局部图像来预测、补偿当前的局部图像，可有效减少帧序列冗余信息。\n运动表示：不同区域的图像使用不同的运动矢量来描述运动信息，运动矢量通过熵编码进行压缩（熵编码在编码过程中不会丢失信息）。\n运动估计：从视频序列中抽取运动信息。\n通用的压缩标准使用基于块的运动估计和运动补偿。")])]),v._v(" "),a("li",[a("p",[v._v("去除空域冗余信息")]),v._v(" "),a("p",[v._v("变换编码：将空域信号变换到另一正交矢量空间，使其相关性下降，数据冗余度减小。\n量化编码：对变换编码产生的变换系数进行量化，控制编码器的输出位率。\n熵编码： 对变换、量化后得到的系数和运动信息，进行进一步的无损压缩。\n视频压缩编码技术可分为两大类：无损压缩和有损压缩。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("无损压缩")]),v._v(" "),a("p",[v._v("无损压缩也称为可逆编码，重构后的数据与原数据完全相同，适用于磁盘文件的压缩等。\n主要采用熵编码方式，包括香农编码、哈夫曼编码和算术编码等。\n<1>香农编码\n香农编码采用信源符号的累计概率分布函数来分配码字，效率不高，实用性不大，但对其他编码方法有很好的理论指导意义。\n<2>哈夫曼编码\n哈夫曼编码完全依据出现概率来构造异字头的平均长度最短的码字。\n基本方法为：先对图像数据扫描一遍，计算出各种像素出现的概率，按概率的大小指定不同长度的唯一码字，由此得到一张该图像的霍夫曼码表。\n编码后的图像数据记录的是每个像素的码字，而码字与实际像素值的对应关系记录在码表中。\n<3>算术编码\n算术编码是用符号的概率和编码间隔两个基本参数来描述的，在给定符号集和符号概率的情况下，算术编码可以给出接近最优的编码结果。\n使用算术编码的压缩算法通常先要对输入符号的概率进行估计，然后再编码，估计越准，编码结果就越接近最优的结果。")])]),v._v(" "),a("li",[a("p",[v._v("有损压缩")]),v._v(" "),a("p",[v._v("有损压缩也称为不可逆编码，重构后的数据与原数据有差异，适用于任何允许有失真的场景，例如视频会议、可视电话、视频广播、视频监控等。\n编码方式包括预测编码、变换编码、量化编码、混合编码等。")])])])])]),v._v(" "),a("h3",{attrs:{id:"编码标准"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#编码标准"}},[v._v("#")]),v._v(" 编码标准")]),v._v(" "),a("p",[v._v("定义：为保证编码的正确性，编码要规范化、标准化，所以就有了编码标准。\n研制视频编码标准的有两大正式组织：ISO/IEC（国际标准化组织）、ITU-T（国际电信联盟通信标准部）。\nISO/IEC 制定的编码标准有：MPEG-1、MPEG-2、MPEG-4、MPEG-7、MPEG-21 和 MPEG-H 等。\nITU-T 制定的编码标准有：H.261、H.262、H.263、H.264 和 H.265 等。\nMPEG-x 和 H.26x 标准的视频编码都是采用有损压缩的混合编码方式，主要区别在于处理图像的分辨率、预测精度、搜索范围、量化步长等参数的不同，所以其应用场合也不同。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("MPEG-x系列")]),v._v(" "),a("p",[v._v('（1）MPEG-1\nMPEG-1 共 5 部分。\n第 2 部分视频编码方案，规定了逐行扫描视频的编码方案。\n第 3 部分音频编码方案，将音频流的压缩分为 3 层并依次增大压缩比，广为流传的 MP3（MPEG-1 Layer 3）就是按照此部分编码方案压缩之后的文件格式。\n（2）MPEG-2\nMPEG-2 共 11 个部分，在 MPEG-1 的基础上提高了码率和质量。\n第 2 部分视频编码方案，规定了隔行扫描视频的编码方案，是和 ITU-T 共同开发的，ITU-T 称其为 H.262。\n第 3 部分音频编码方案，延续了 MPEG-1 的 3 层压缩方案，压缩后文件格式仍未 MP3，但在压缩算法上有所改进。\n第 7 部分首次提出 AAC（MPEG Advanced Audio Coding）编码，目的以更小的容量和更好的音质取代 MP3 格式。\n（3）MPEG-4\nMPEG-4 共 27 个部分，更加注重多媒体系统的交互性和灵活性。\n第 3 部分音频编码方案，优化了 AAC 编码算法，并在推出后逐渐取代 MP3，比如和视频封装在一起的音频优先考虑 AAC 格式，但就民用而言大部分还是使用 MP3 格式。\n第 10 部分提出 AVC（Advanced Video Coding）编码，是和 ITU-T 共同开发的，ITU-T 称其为 H.264。\n第 14 部分提出了 MP4 格式封装，官方文件后缀名是 ".mp4"，还有其他的以 mp4 为基础进行的扩展或缩水版本的格式，包括：M4V,  3GP, F4V 等。\n（4）MPEG-7\nMPEG-7 不同于 MPEG-1、MPEG-2、MPEG-4，它不是音视频压缩标准。\nMPEG-7 被称为 "多媒体内容描述接口"，目的就是产生一种描述多媒体信息的标准，并将该描述与所描述的内容相联系，以实现快速有效的检索。\n（5）MPEG-12\nMPEG-12 其实就是一些关键技术的集成，通过这种集成环境对全球数字媒体资源进行管理，实现内容描述、创建、发布、使用、识别、收费管理、版权保护等功能。\n（6）MPEG-H\nMPEG-H 包含了 1 个数字容器标准、1 个视频压缩标准、1 个音频压缩标准和 2 个一致性测试标准。\n其中视频压缩标准为高效率视频编码（HEVC），和 ITU-T 联合开发，相比 H.264/MPEG-4 AVC 数据压缩率增加了 1 倍。')])]),v._v(" "),a("li",[a("p",[v._v("H.26x 系列")]),v._v(" "),a("p",[v._v("1）H.261\nH.261 是第一个实用的数字视频编码标准，使用了混合编码框架，包括了基于运动补偿的帧间预测，基于离散余弦变换的空域变换编码，量化，zig-zag 扫描和熵编码。\nH.261 的设计相当成功，之后的视频编码国际标准基本上都是基于 H.261 的设计框架，包括 MPEG-1，MPEG-2／H.262，H.263，甚至 H.264。\n（2）H.262\nH.262 由 MPEG-1 扩充而来，支持隔行扫描，在技术内容上和 MPEG-2 视频标准一致，DVD 就是采用了该技术。\n（3）H.263\nH.263 是一种用于视频会议的低码率视频编码标准，在 H.261 基础上发展而来。\n与 H.261 相比采用了半象素的运动补偿，并增加了 4 种有效的压缩编码模式，在低码率下能够提供比 H.261 更好的图像效果。\nH.263 于 1995 年推出第一版，后续在 1998 年和 2000 年还推出了第二版 H.263+、第三版 H.263++ 。\n（4）H.264\n（5）H.265")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("H.264")]),v._v(" "),a("p",[v._v("H.264 又称为 MPEG-4 第 10 部分，即 MPEG-4 AVC，它是一种面向块，基于运动补偿的视频编码标准。\n于 2003 年正式发布，现在已经成为高精度视频录制、压缩和发布的最常用格式之一。\nH.264 可以在低码率情况下提供高质量的视频图像，相比 H.263 可节省 50% 的码率。\n相比 H.263，H.264 不需设置较多的编码选项，降低了编码的复杂度。\nH.264 可以根据不同的环境使用不同的传输和播放速率，并且提供了丰富的错误处理工具，可以很好的控制或消除丢包和误码。\nH.264 性能的改进是以增加复杂性为代价而获得的，H.264 编码的计算复杂度大约相当于 H.263 的 3 倍，解码复杂度大约相当于 H.263 的 2 倍。\nH.264 协议中定义了三种帧，分别为 I 帧、P 帧以及 B 帧。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("帧种类")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("IDR帧")]),v._v(" "),a("p",[v._v("把第一个首个I帧叫IDR。当解码器解码到 IDR 图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列。")])]),v._v(" "),a("li",[a("p",[v._v("I帧")]),v._v(" "),a("p",[v._v("I帧即帧内编码帧、关键帧，可以理解为一帧画面的完整保留，解码时只需要本帧数据就可以完成，不需要参考其他画面，数据量比较大。  保存完整画面。数据量比较大。解码只需要本帧就可以。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("一帧图像")]),v._v(" "),a("p",[v._v("一帧图像划分成一个或多个片")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("片")]),v._v(" "),a("p",[v._v("每片包含整数个宏块，最多包含整个图像的宏块，片的目的是为了限制五码的扩算和传输，使编码片相互间保持独立。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("I宏块")]),v._v(" "),a("p",[v._v("多个块组成一个宏块，通常是16个块组成一个宏块")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("16块")]),v._v(" "),a("ul",[a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("...")])])]),v._v(" "),a("li",[a("p",[v._v("16块")])]),v._v(" "),a("li",[a("p",[v._v("16块")])]),v._v(" "),a("li",[a("p",[v._v("...")])])])]),v._v(" "),a("li",[a("p",[v._v("B宏块")]),v._v(" "),a("p",[v._v("多个块组成一个宏块，通常是16个块组成一个宏块")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("16块")]),v._v(" "),a("ul",[a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("...")])])]),v._v(" "),a("li",[a("p",[v._v("16块")])]),v._v(" "),a("li",[a("p",[v._v("16块")])]),v._v(" "),a("li",[a("p",[v._v("...")])])])]),v._v(" "),a("li",[a("p",[v._v("P宏块")]),v._v(" "),a("p",[v._v("多个块组成一个宏块，通常是16个块组成一个宏块")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("16块")]),v._v(" "),a("ul",[a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("块(4x4像素)")]),v._v(" "),a("li",[v._v("...")])])]),v._v(" "),a("li",[a("p",[v._v("16块")])]),v._v(" "),a("li",[a("p",[v._v("16块")])]),v._v(" "),a("li",[a("p",[v._v("...")])])])])])]),v._v(" "),a("li",[a("p",[v._v("...")])])])])])]),v._v(" "),a("li",[a("p",[v._v("P帧")]),v._v(" "),a("p",[v._v("P帧即前向预测编码帧，记录当前帧跟上一关键帧（或P帧）的差别，解码时依赖之前缓存的画面，叠加上本帧定义的差别，才能生成最终画面，数据量较 I 帧小很多。")])]),v._v(" "),a("li",[a("p",[v._v("B帧")]),v._v(" "),a("p",[v._v("B帧即双向预测编码帧，记录当前帧跟前后帧的差别，解码时依赖前面的I帧（或P帧）和后面的P帧，数据量比I帧和P帧小很多。\n数据压缩比大约为：  I帧：P帧：B帧  =  7：20：50，可见 P 帧和 B 帧极大的节省了数据量，节省出来的空间可以用来多保存一些 I 帧，以实现在相同码率下，提供更好的画质。")])])])]),v._v(" "),a("li",[a("p",[v._v("片")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("I片")]),v._v(" "),a("ul",[a("li",[v._v("只包含I宏块")])])]),v._v(" "),a("li",[a("p",[v._v("P片")]),v._v(" "),a("ul",[a("li",[v._v("包含P和I宏块")])])]),v._v(" "),a("li",[a("p",[v._v("B片")]),v._v(" "),a("ul",[a("li",[v._v("包含B和I宏块")])])]),v._v(" "),a("li",[a("p",[v._v("SP片")]),v._v(" "),a("ul",[a("li",[v._v("用于不同编码流之间的切换")])])]),v._v(" "),a("li",[a("p",[v._v("SI片")]),v._v(" "),a("ul",[a("li",[v._v("特殊类型的编码宏块")])])])])]),v._v(" "),a("li",[a("p",[v._v("组成部分NALU(Nal Unit)")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("开始码")]),v._v(" "),a("ul",[a("li",[v._v('必须是"00 00 00 01" 或"00 00 01"')])])]),v._v(" "),a("li",[a("p",[v._v("NAL类型")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("1")]),v._v(" "),a("ul",[a("li",[v._v("非IDR图像中不采用数据划分的片段，表示这是一个P帧或B帧，个人理解这句话的意思是，它不能用于数据划分，所以它不是一个I帧")])])]),v._v(" "),a("li",[a("p",[v._v("5")]),v._v(" "),a("ul",[a("li",[v._v("IDR图像的片段，表示这是一个I帧，I帧前面必须有SPS和PPS数据，个人理解是因为它能用来前后数据划分，所以是一个I帧")])])]),v._v(" "),a("li",[a("p",[v._v("7")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("序列参数集(SPS)")]),v._v(" "),a("p",[v._v("SPS包含的是针对一连续编码视频序列的参数，如seq_parameter_set_id、帧数及POC的约束、参数帧数目、解码图像尺寸和帧场编码模式选择标识等。")])])])]),v._v(" "),a("li",[a("p",[v._v("8")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("图像参数集（PPS）")]),v._v(" "),a("p",[v._v("PPS对应的是一个序列中某一副图像或者某几幅图像，参数如标识符pic_parameter_set_id、可选的seq_parameter_set_id、熵编码模式选择标识、片组数组、初始量化参数和去方块铝箔系数调整标识等。")])])])])])]),v._v(" "),a("li",[a("p",[v._v("视频数据")])])])])])]),v._v(" "),a("li",[a("p",[v._v("H.265")]),v._v(" "),a("p",[v._v("H.265 即高效视频编码（High Efficiency Video Coding ，简称 HEVC），于 2013 年正式推出。\nH.265 编码架构和 H.264 相似，主要也包含，帧内预测、帧间预测、转换、量化、去区块滤波器、熵编码等模块。\nH.265 编码架构整体被分为编码单位、预测单位和转换单位。\nH.265 在 H.264 的基础之上，使用先进的技术用以改善码流、编码质量、延时和算法复杂度之间的关系，达到最优化设置。\n在码率减少 51-74% 的情况下，H.265 编码视频的质量还能与 H.264 编码视频近似甚至更好。\nH.265 可以在有限带宽下传输更高质量的网络视频，智能手机、平板机等移动设备将能直接在线播放 1080p 的全高清视频，让网络视频跟上了显示屏 “高分辨率化” 的脚步。")])])])])]),v._v(" "),a("h3",{attrs:{id:"视频封装格式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频封装格式"}},[v._v("#")]),v._v(" 视频封装格式")]),v._v(" "),a("p",[v._v("视频封装格式如 mp4、mkv，用来存储或传输编码数据，可以理解成一个容器。\n封装就是按照一定规则把音视频、字幕等数据组织起来，包含编码类型等公共信息，播放器可以按照这些信息来匹配解码器、同步音视频。\n不同的封装格式支持的视音频编码格式是不一样的，比如 MKV 格式支持比较多，RMVB 则主要支持 Real 公司的视音频编码格式。")]),v._v(" "),a("h3",{attrs:{id:"视频解码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频解码"}},[v._v("#")]),v._v(" 视频解码")]),v._v(" "),a("p",[v._v("定义：将视频压缩编码过的数据，解压缩成为视频原始数据，即视频编码的反过程。")]),v._v(" "),a("p",[v._v("对于一个播放器来说，很重要的一个指标就是能支持多少种视频解码。")]),v._v(" "),a("h3",{attrs:{id:"视频播放原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频播放原理"}},[v._v("#")]),v._v(" 视频播放原理")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("解封装")]),v._v(" "),a("p",[v._v("就是将输入的封装格式的数据，分离成为音频压缩编码数据和视频压缩编码数据。例如，FLV 格式的数据，经过解封装操作后，输出 H.264 编码的视频码流和 AAC 编码的音频码流。")])]),v._v(" "),a("li",[a("p",[v._v("解码")]),v._v(" "),a("p",[v._v("将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含 AAC，MP3，AC-3 等等，视频的压缩编码标准则包含 H.264，MPEG2，VC-1 等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如 YUV420P，RGB 等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如 PCM 数据。")])]),v._v(" "),a("li",[a("p",[v._v("视音频同步")]),v._v(" "),a("p",[v._v("根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。")])])]),v._v(" "),a("h3",{attrs:{id:"视频与流媒体"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频与流媒体"}},[v._v("#")]),v._v(" 视频与流媒体")]),v._v(" "),a("p",[v._v("上面播放原理中分析的是本地视频文件，如果播放的是互联网上的视频，步骤则为：解协议，解封装，解码音视频，音视频同步，多了一个解协议的步骤。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("解协议")]),v._v(" "),a("p",[v._v("解协议：将流媒体协议的数据，解析为标准的相应的封装格式数据。")]),v._v(" "),a("p",[v._v("视音频在网络上传播的时候，常常采用各种流媒体协议，例如 HTTP，RTMP， MMS 等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。")]),v._v(" "),a("p",[v._v("这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。")]),v._v(" "),a("p",[v._v("解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用 RTMP 协议传输的数据，经过解协议操作后，输出 FLV 格式的数据。")])])]),v._v(" "),a("h3",{attrs:{id:"time-base"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#time-base"}},[v._v("#")]),v._v(" time_base")]),v._v(" "),a("p",[v._v("如果把1秒分为25等份，你可以理解就是一把尺，那么每一格表示的就是1/25秒。此时的time_base={1，25}\n如果你是把1秒分成90000份，每一个刻度就是1/90000秒，此时的time_base={1，90000}。所谓时间基表示的就是每个刻度是多少秒")]),v._v(" "),a("h3",{attrs:{id:"pts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pts"}},[v._v("#")]),v._v(" PTS")]),v._v(" "),a("p",[v._v("PTS：Presentation Time Stamp。PTS主要用于度量解码后的视频帧什么时候被显示出来")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("pts的值就是占多少个时间刻度（时间基）。它的单位不是秒，而是时间刻度。只有pts乘以time_base两者同时在一起，才能表达出时间是多少。")]),v._v(" "),a("ul",[a("li",[v._v("根据pts来计算一桢在整个视频中的时间位置：\ntimestamp(秒) = pts * av_q2d(st->time_base)")])])])]),v._v(" "),a("h3",{attrs:{id:"dts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dts"}},[v._v("#")]),v._v(" DTS")]),v._v(" "),a("p",[v._v("DTS：Decode Time Stamp。DTS主要是标识读入内存中的ｂｉｔ流在什么时候开始送入解码器中进行解码")]),v._v(" "),a("h3",{attrs:{id:"duration"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#duration"}},[v._v("#")]),v._v(" duration")]),v._v(" "),a("ul",[a("li",[v._v("计算帧的长度：\ntime(秒) = st->duration * av_q2d(st->time_base)")])]),v._v(" "),a("h3",{attrs:{id:"视频帧和游戏帧的不同"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频帧和游戏帧的不同"}},[v._v("#")]),v._v(" 视频帧和游戏帧的不同")]),v._v(" "),a("ul",[a("li",[v._v("视频帧是连续的画面，最低要求24fps")]),v._v(" "),a("li",[v._v("游戏帧是一个静止的画面，最低要求60fps")])]),v._v(" "),a("h3",{attrs:{id:"采集视频制式选择"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#采集视频制式选择"}},[v._v("#")]),v._v(" 采集视频制式选择")]),v._v(" "),a("p",[v._v("如果录制的视频不是在电视机上播放，而仅仅只是在电脑上播放，那么选择哪种制式都没有问题，一般根据帧率来决定，比如想要更高的帧率，则可以选择NTSC制式，如果想要在电视机上直接播放录制的视频，最好使用PAL制式")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("PAL")]),v._v(" "),a("ul",[a("li",[v._v("每秒25帧，适用于我国电视机，电压220V，50Hz")])])]),v._v(" "),a("li",[a("p",[v._v("NTSC")]),v._v(" "),a("ul",[a("li",[v._v("每秒30帧，主要适用于北美国家的电视机，北美电压是110V，60Hz")])])])]),v._v(" "),a("h3",{attrs:{id:"常见媒体的fps帧率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#常见媒体的fps帧率"}},[v._v("#")]),v._v(" 常见媒体的FPS帧率")]),v._v(" "),a("ul",[a("li",[v._v("电影：24fps")]),v._v(" "),a("li",[v._v("电视（PAL）：25fps")]),v._v(" "),a("li",[v._v("电视（NTSL）：30fps")])]),v._v(" "),a("h3",{attrs:{id:"gop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gop"}},[v._v("#")]),v._v(" GOP")]),v._v(" "),a("p",[v._v("表示多少秒一个I帧")]),v._v(" "),a("h3",{attrs:{id:"avc"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#avc"}},[v._v("#")]),v._v(" AVC")]),v._v(" "),a("h3",{attrs:{id:"大端和小端"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大端和小端"}},[v._v("#")]),v._v(" 大端和小端")]),v._v(" "),a("p",[v._v("iOS系统默认存储的是小端数据")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("小端")]),v._v(" "),a("ul",[a("li",[v._v("高字节在高地址, 低字节在低地址")])])]),v._v(" "),a("li",[a("p",[v._v("大端")]),v._v(" "),a("ul",[a("li",[v._v("高字节在低地址, 低字节在高地址")])])])]),v._v(" "),a("h2",{attrs:{id:"足迹效果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#足迹效果"}},[v._v("#")]),v._v(" 足迹效果")]),v._v(" "),a("h3",{attrs:{id:"caemitterlayer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#caemitterlayer"}},[v._v("#")]),v._v(" CAEmitterLayer")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("[CAEmitterLayer layer]")])]),v._v(" "),a("li",[a("p",[v._v("emitterPosition")]),v._v(" "),a("ul",[a("li",[v._v("发射器在xy平面的中心位置")])])]),v._v(" "),a("li",[a("p",[v._v("emitterSize")]),v._v(" "),a("ul",[a("li",[v._v("发射器的尺寸大小")])])]),v._v(" "),a("li",[a("p",[v._v("renderMode")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("渲染模式")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("kCAEmitterLayerUnordered")]),v._v(" "),a("ul",[a("li",[v._v("粒子是无序出现的，多个发射源将混合")])])]),v._v(" "),a("li",[a("p",[v._v("kCAEmitterLayerOldestFirst")]),v._v(" "),a("ul",[a("li",[v._v("声明久的粒子会被渲染在最上层")])])]),v._v(" "),a("li",[a("p",[v._v("kCAEmitterLayerOldestLast")]),v._v(" "),a("ul",[a("li",[v._v("年轻的粒子会被渲染在最上层")])])]),v._v(" "),a("li",[a("p",[v._v("kCAEmitterLayerBackToFront")]),v._v(" "),a("ul",[a("li",[v._v("粒子的渲染按照Z轴的前后顺序进行")])])]),v._v(" "),a("li",[a("p",[v._v("kCAEmitterLayerAdditive")]),v._v(" "),a("ul",[a("li",[v._v("进行粒子混合")])])])])])])]),v._v(" "),a("li",[a("p",[v._v("preservesDepth")]),v._v(" "),a("ul",[a("li",[v._v("开启三维效果")])])]),v._v(" "),a("li",[a("p",[v._v("创建粒子")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("[CAEmitterCell emitterCell]")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("birthRate")]),v._v(" "),a("ul",[a("li",[v._v("粒子的创建速率，默认为1/s")])])]),v._v(" "),a("li",[a("p",[v._v("lifetime")]),v._v(" "),a("ul",[a("li",[v._v("粒子存活时间")])])]),v._v(" "),a("li",[a("p",[v._v("lifetimeRange")]),v._v(" "),a("ul",[a("li",[v._v("粒子的生存时间容差")])])]),v._v(" "),a("li",[a("p",[v._v("contents")]),v._v(" "),a("ul",[a("li",[v._v("粒子显示的内容，传CGImage")])])]),v._v(" "),a("li",[a("p",[v._v("color")]),v._v(" "),a("ul",[a("li",[v._v("颜色，传CGColor")])])]),v._v(" "),a("li",[a("p",[v._v("name")]),v._v(" "),a("ul",[a("li",[v._v("粒子的名字")])])]),v._v(" "),a("li",[a("p",[v._v("velocity")]),v._v(" "),a("ul",[a("li",[v._v("粒子的运行速度")])])]),v._v(" "),a("li",[a("p",[v._v("velocityRange")]),v._v(" "),a("ul",[a("li",[v._v("粒子速度的容差")])])]),v._v(" "),a("li",[a("p",[v._v("emissionLongitude")]),v._v(" "),a("ul",[a("li",[v._v("粒子在xy平面的发射角度")])])]),v._v(" "),a("li",[a("p",[v._v("emissionRange")]),v._v(" "),a("ul",[a("li",[v._v("粒子发射角度的容差")])])]),v._v(" "),a("li",[a("p",[v._v("scale")]),v._v(" "),a("ul",[a("li",[v._v("缩放比例")])])])])])])]),v._v(" "),a("li",[a("p",[v._v("emitterCells")]),v._v(" "),a("ul",[a("li",[v._v("创建的粒子添加到该数组")])])])]),v._v(" "),a("h2",{attrs:{id:"视频播放原理-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频播放原理-2"}},[v._v("#")]),v._v(" 视频播放原理")]),v._v(" "),a("h3",{attrs:{id:"封装格式数据mp4、flv"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#封装格式数据mp4、flv"}},[v._v("#")]),v._v(" 封装格式数据mp4、flv...")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("解封装")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("视频压缩数据H264、H265...")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("视频解码")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("视频像素数据YUV...")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("音视频同步")]),v._v(" "),a("ul",[a("li",[v._v("视频输出")])])])])])])])])]),v._v(" "),a("li",[a("p",[v._v("音频压缩数据AAC、MP3...")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("音频解码")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("音频采样数据PCM...")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("音视频同步")]),v._v(" "),a("ul",[a("li",[v._v("音频输出")])])])])])])])])])])])]),v._v(" "),a("h2",{attrs:{id:"视频采集输出数据格式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频采集输出数据格式"}},[v._v("#")]),v._v(" 视频采集输出数据格式")]),v._v(" "),a("h3",{attrs:{id:"yuv优点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#yuv优点"}},[v._v("#")]),v._v(" YUV优点")]),v._v(" "),a("p",[v._v("YUV的原理是把亮度与色度分离，研究证明,人眼对亮度的敏感超过色度。利用这个原理，可以把色度信息减少一点，人眼也无法查觉这一点。YUV三个字母中，其中”Y”表示明亮度（Lumina nce或Luma），也就是灰阶值；而”U”和”V”表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色")]),v._v(" "),a("ul",[a("li",[v._v("彩色YUV图像转黑白YUV图像转换非常简单，这一特性用在与电视信号上")]),v._v(" "),a("li",[v._v("YUV是数据总尺寸小于RGB格式")])]),v._v(" "),a("h3",{attrs:{id:"rgb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rgb"}},[v._v("#")]),v._v(" RGB")]),v._v(" "),a("h2",{attrs:{id:"为什么要进行视频编码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么要进行视频编码"}},[v._v("#")]),v._v(" 为什么要进行视频编码？")]),v._v(" "),a("p",[v._v("首先我们假设一种场景， 采集一分钟数据，需要多大的空间来存储。\n1、视频分辨率是 1280 * 720.\n2、一秒钟之内至少需要16帧画面（正常开发通常会采集30帧），为了不让用户感受明显卡顿现象.\n3、采用NV12 (YUV420)输出格式计算。（YUV420为4个Y共用一个U和V，Y分量为全采样，即1字节，U分量和V分量只有Y分量的四分之一，即U分量和V分量的大小均为1/4字节，也就是说一张1像素的YUV420图像大小为：(3/2)=1.5字节。）\n计算结果： 1280 * 720 * 1.5 * 16 * 60 = 1296 M")]),v._v(" "),a("p",[v._v("作者：lyking\n链接：https://www.jianshu.com/p/15c12c3deb8f\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。")]),v._v(" "),a("h3",{attrs:{id:"一秒钟采集的原生yuv420数据-在分辨率为1280x720时-大概为12807201-5-30帧-40mb-通过设置码率-对原生数据进行采样编码处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一秒钟采集的原生yuv420数据-在分辨率为1280x720时-大概为12807201-5-30帧-40mb-通过设置码率-对原生数据进行采样编码处理"}},[v._v("#")]),v._v(" 一秒钟采集的原生YUV420数据，在分辨率为1280x720时，大概为1280"),a("em",[v._v("720")]),v._v("1.5*30帧=40MB，通过设置码率，对原生数据进行采样编码处理")]),v._v(" "),a("h2",{attrs:{id:"h264硬编码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#h264硬编码"}},[v._v("#")]),v._v(" H264硬编码")]),v._v(" "),a("p",[v._v('https://www.jianshu.com/p/15c12c3deb8f。 H264采用的核心算法是帧内压缩和帧间压缩，帧内压缩是生成I帧的算法，帧间压缩是生成B帧和P帧的算法。H264原始麻溜是由一个接一个的NALU(Nal Unit)组成。NALU = 开始码+NAL类型+视频数据。开始码必须是"00 00 00 01"或"00 00 01"。  NAL类型：主要用到的有类型1、5、7、8。1表示非IDR图像中不采用数据划分得片段。5表示IDR图像的片段，。7表示序列参数集(SPS)。8表示图像参数集(PPS)。')]),v._v(" "),a("h3",{attrs:{id:"通过vtcompressionsessioncreate创建编码器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#通过vtcompressionsessioncreate创建编码器"}},[v._v("#")]),v._v(" 通过VTCompressionSessionCreate创建编码器")]),v._v(" "),a("p",[v._v("allocator：内存分配器，填NULL为默认分配器\nwidth、height：视频帧像素的宽高，如果编码器不支持这个宽高的话可能会改变\ncodecType：编码类型，枚举\nencoderSpecification：指定特定的编码器，填NULL的话由VideoToolBox自动选择\nsourceImageBufferAttributes：源像素缓冲区的属性，如果这个参数有值的话，VideoToolBox会创建一个缓冲池，不需要缓冲池可以设置为NULL\ncompressedDataAllocator：压缩后数据的内存分配器，填NULL使用默认分配器\noutputCallback：视频编码后输出数据回调函数\noutputCallbackRefCon：回调函数中的自定义指针，我们通常传self，在回调函数中就可以拿到当前类的方法和属性了\ncompressionSessionOut：编码器句柄，传入编码器的指针")]),v._v(" "),a("p",[v._v("作者：lyking\n链接：https://www.jianshu.com/p/15c12c3deb8f\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("通过VTSessionSetProperty设置编码器属性")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("设置完属性调用VTCompressionSessionPrepareToEncodeFrames准备编码")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("输入采集到的视频数据，调用VTCompressionSessionEncodeFrame进行编码")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("获取到编码后的数据并进行处理")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("调用VTCompressionSessionCompleteFrames停止编码器")]),v._v(" "),a("ul",[a("li",[v._v("调用VTCompressionSessionInvalidate销毁编码器")])])])])])])])])])])])]),v._v(" "),a("h2",{attrs:{id:"yuv"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#yuv"}},[v._v("#")]),v._v(" YUV")]),v._v(" "),a("p",[v._v("YUV，亦称YCrCb，分为三个分量，Y表示明亮度，也就是灰度值；而“U”和“V”表示的则是色度。作用是描述影像色彩及饱和度，用于指定像素的颜色。")]),v._v(" "),a("h3",{attrs:{id:"planar"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#planar"}},[v._v("#")]),v._v(" planar")]),v._v(" "),a("p",[v._v("平面格式，分为平面和双平面。先连续存储所有像素点的Y，紧接着存储所有像素点的U，随后是所有像素点的V。使用三个数组分开存放YUV三个分量，就像是一个三维平面一样。")]),v._v(" "),a("h3",{attrs:{id:"packed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#packed"}},[v._v("#")]),v._v(" packed")]),v._v(" "),a("p",[v._v("每个像素点的Y、U、V是连续交错存储的。将YUV分量存放在同一个数组中，通常是几个相邻的像素组成一个宏像素（macro-pixel）")]),v._v(" "),a("h3",{attrs:{id:"种类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#种类"}},[v._v("#")]),v._v(" 种类")]),v._v(" "),a("p",[v._v("有一种表示法可用来描述 U 和 V 与 Y 的采样频率比例，这个表示法称为 A:B:C 表示法")]),v._v(" "),a("ul",[a("li",[a("p",[v._v("YUV444")]),v._v(" "),a("ul",[a("li",[v._v("4:4:4，YUV三个信道抽样率相同，因此在生成的图像里，每个像素三个分量信息完整，经过8比特量化后，未经压缩占用3字节。")])])]),v._v(" "),a("li",[a("p",[v._v("YUV422")]),v._v(" "),a("ul",[a("li",[v._v("当出现4个YUV数据(一个YUV代表一个像素点)时，每存放4个Y时，只存储2个U以及2个V")])])]),v._v(" "),a("li",[a("p",[v._v("YUV420")]),v._v(" "),a("ul",[a("li",[v._v("每存放4个Y时，只存放2个U，不存放V，下一行再存放4个Y时，不存放U，只存放2个V，也就是隔行存储，占用空间跟YUV411一样")])])]),v._v(" "),a("li",[a("p",[v._v("YUV411")]),v._v(" "),a("ul",[a("li",[v._v("4:1:1比较常用，意义为每个像素点保存一个8bit的亮度值也就是Y值。每2*2个像素点保存一个Cr和Cb的值。")])])]),v._v(" "),a("li",[a("p",[v._v("YUV422P")]),v._v(" "),a("p",[v._v("属于YUV422，它是一种Plane模式，即平面模式，先存所有的Y，再存所有的U，最后存所有的V")])]),v._v(" "),a("li",[a("p",[v._v("YV12和YU12")]),v._v(" "),a("p",[v._v("属于YUV420，只不过它是一种Plane模式，即平面模式，它不是YUV交替存储的，而是先存所有的Y，再存所有的U，最后存所有的V，在同一个平面内")])]),v._v(" "),a("li",[a("p",[v._v("NV12、NV21")]),v._v(" "),a("p",[v._v("双平面模式，即Y和UV分为两个Plane，但是UV为交错存储，而不是分为三个plane。")])])]),v._v(" "),a("h2",{attrs:{id:"色彩组成"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#色彩组成"}},[v._v("#")]),v._v(" 色彩组成")]),v._v(" "),a("h3",{attrs:{id:"亮度y"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#亮度y"}},[v._v("#")]),v._v(" 亮度Y")]),v._v(" "),a("h3",{attrs:{id:"色调-cr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#色调-cr"}},[v._v("#")]),v._v(" 色调(Cr)")]),v._v(" "),a("p",[v._v("大致意思是属于哪种颜色，反映了输入信号红色部分 与RGB信号亮度值之间的差异")]),v._v(" "),a("h3",{attrs:{id:"饱和度-cb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#饱和度-cb"}},[v._v("#")]),v._v(" 饱和度(Cb)")]),v._v(" "),a("p",[v._v("大致意思是颜色深度，Cb反映的是蓝色部分与RGB信号亮度值之间的差异")]),v._v(" "),a("p",[a("em",[v._v("XMind - Trial Version")])])])}),[],!1,null,null,null);_.default=i.exports}}]);